{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4a056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499124cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nhsiao:chingwei1%7e@\n",
    "#! pip install transformers --proxy=http://fetfw.fareastone.com.tw:8080 --trusted-host=pypi.python.org --trusted-host=pypi.org --trusted-host=files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5e5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install transformers[sentencepiece] --proxy=http://nhsiao:chingwei1%7e@fetfw.fareastone.com.tw:8080 --trusted-host=pypi.python.org --trusted-host=pypi.org --trusted-host=files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e00312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install datasets==1.18.3 --proxy=http://fetfw.fareastone.com.tw:8080 --trusted-host=pypi.python.org --trusted-host=pypi.org --trusted-host=files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75359eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install torch --proxy=http://fetfw.fareastone.com.tw:8080 --trusted-host=pypi.python.org --trusted-host=pypi.org --trusted-host=files.pythonhosted.org\n",
    "# pip install torchvision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6d3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')\n",
    "tokenizer = AutoTokenizer.from_pretrained('../module/roberta-base-finetuned-chinanews-chinese/')\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed804654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca3e22",
   "metadata": {},
   "source": [
    "### 產生train & val資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1009160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = 'train_v3(drop).csv' \n",
    "\n",
    "# df = pd.read_csv(datapath)\n",
    "# df.rename(columns={'Drop' : 'label','content':'text'},inplace=True)\n",
    " \n",
    "# df['content'] = df['title']+'[sep]'+ df['text']  \n",
    "# df['label'].value_counts()  # 看drop資料數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db40107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[:,['label','content']]\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aca3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(112)\n",
    "## 拆分成df_train, df_val, df_test\n",
    "# df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "#                                      [int(.8*len(df)), int(.9*len(df))])\n",
    "# print(len(df_train),len(df_val),len(df_test))\n",
    "\n",
    "\n",
    "# #拆分成df_train, df_val\n",
    "# df_train, df_val = np.split(df.sample(frac=1, random_state=42), \n",
    "#                                      [int(.8*len(df))])\n",
    "# print(len(df_train),len(df_val)) #, len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba64a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('/home/jovyan/at102-group4/model1_drop/train2.csv',index=False)\n",
    "# df_val.to_csv('/home/jovyan/at102-group4/model1_drop/val2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc516d34",
   "metadata": {},
   "source": [
    "### test資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7bb173",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_2022-03-18.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入test資料\n",
    "import datetime\n",
    "\n",
    "\n",
    "date = str(datetime.date.today())\n",
    "date_today = 'data_'+ date + '.csv'\n",
    "\n",
    "datapath_test_file = \"./../data/\"\n",
    "datapath_test = os.path.join(datapath_test_file,date_today) \n",
    "\n",
    "df_test_all = pd.read_csv(datapath_test)\n",
    "date_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d70fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 製造一份相同格式的測試資料，僅留標題+內文\n",
    " \n",
    "data = df_test_all['title']+'[sep]'+ df_test_all['content']\n",
    "df_test = pd.DataFrame(data=data[:20],columns=['content'])\n",
    "df_test['label'] = None\n",
    "df_test = df_test[['label','content']]\n",
    "df_test.dropna(how='all', inplace=True)\n",
    "\n",
    "# 存檔處理後的test\n",
    "# save_path_file = '/home/jovyan/at102-group4/model1_drop/test/'\n",
    "save_path_file = './../data/test/'\n",
    "\n",
    "save_path = os.path.join(save_path_file,'test_'+date+'.csv')\n",
    "df_test.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5bf26",
   "metadata": {},
   "source": [
    "### 載入train val test資料集，並經過tokenize，製成可處理之型式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a569d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此方法適用jupyter notebook, 不適用 docker\n",
    "# data=load_dataset('csv', data_files={'train':['/home/ec2-user/SageMaker/poas/data/test/train2.csv'], \n",
    "#                                      'valid':['/home/ec2-user/SageMaker/poas/data/test/val2.csv'],\n",
    "#                                      'test':[save_path]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3c42e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-02849fe87e281f0f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\noc\\.cache\\huggingface\\datasets\\csv\\default-02849fe87e281f0f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1025.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\noc\\.cache\\huggingface\\datasets\\csv\\default-02849fe87e281f0f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data=load_dataset('csv', data_files={\n",
    "                                     'test':[save_path]}) \n",
    "                                     #'train':['./../data/test/train2.csv'], \n",
    "                                    #  'valid':['./../data/test/val2.csv'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99ac8226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36606489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 31.11ba/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(data:dict):\n",
    "    return tokenizer(data['content'],padding=True,truncation=True, max_length=512)\n",
    "\n",
    "tokenized_data=data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "341ba101",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = tokenized_data.remove_columns(['content'])\n",
    "tokenized_data = tokenized_data.rename_column('label','labels')\n",
    "tokenized_data.set_format('torch',device='cpu')\n",
    "tokenized_data['test'].column_names\n",
    "tokenized_data.set_format('torch',device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "277ebb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCHSIZE = 8\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     tokenized_data[\"train\"], shuffle=True, batch_size=BATCHSIZE, collate_fn=data_collator\n",
    "# )\n",
    "# valid_dataloader = DataLoader(\n",
    "#     tokenized_data[\"valid\"], shuffle=False, batch_size=BATCHSIZE, collate_fn=data_collator\n",
    "# )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_data[\"test\"], shuffle=False, batch_size=BATCHSIZE, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d506651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     break\n",
    "# {k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c87989",
   "metadata": {},
   "source": [
    "### RoBERTa_model定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59db01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45fe2a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): RoBERTaClass(\n",
       "    (l1): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (l2): Dropout(p=0.3, inplace=False)\n",
       "    (l3): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RoBERTa_model = AutoModelForSequenceClassification.from_pretrained('../module/roberta-base-finetuned-chinanews-chinese')\n",
    "# for param in RoBERTa_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "class RoBERTaClass(torch.nn.Module):\n",
    "    def __init__(self):  # 建造layer積木\n",
    "        super(RoBERTaClass, self).__init__()\n",
    "        self.l1 = RoBERTa_model.base_model\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 2)  # dense layer類別數量:2\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):  # 組裝積木\n",
    "        pooler_output = self.l1(input_ids, attention_mask, token_type_ids)[1]\n",
    "        output_2 = self.l2(pooler_output)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "    \n",
    "model = RoBERTaClass()\n",
    "model.load_state_dict(torch.load('./save_test_v2.pth', map_location=torch.device('cpu'))) \n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbb89186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function定義\n",
    "\n",
    "LEARNING_RATE = 3e-05\n",
    "\n",
    "def loss_fn(output, labels):\n",
    "    return torch.nn.CrossEntropyLoss()(output, labels)\n",
    "\n",
    "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79e95987",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train() #將 model 設為 training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    for data in tqdm(train_dataloader):\n",
    "        input_ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        attention_mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        labels = data['labels'].to(device, dtype = torch.long)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    train_loss = total_loss/len(train_dataloader)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'Epoch:{epoch+1}, Trianing Loss:{total_loss}')\n",
    "    \n",
    "    # return train_loss 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed486434",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_losses = []\n",
    "eval_accu = []\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "def evaluation(eval_data):\n",
    "    model.eval() #將 model 設為 evaluation mode\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    print('Evaluating...')\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(eval_data):\n",
    "            input_ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            attention_mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            labels = data['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "            print(data)\n",
    "            print(len(input_ids))\n",
    "            print(token_type_ids)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            _, predict = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predict.eq(labels).sum().item()\n",
    "            # loss = loss_fn(outputs, labels)\n",
    "            # total_loss += loss.item()\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predict.cpu().numpy())\n",
    "            \n",
    "    # accu = 100.*correct/total\n",
    "    # eval_loss = total_loss/len(eval_data)\n",
    "    # eval_losses.append(eval_loss)\n",
    "    # eval_accu.append(accu)\n",
    "    # print(f'Evaluation Loss:{total_loss}, Accuracy:{accu:.3f}%')\n",
    "    \n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37112675",
   "metadata": {},
   "source": [
    "### 訓練及預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "680bcc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c54a9bc2074461d9458f5eb9e249469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([nan, nan, nan, nan, nan, nan, nan, nan]), 'input_ids': tensor([[ 101, 1071, 2179,  ...,    0,    0,    0],\n",
      "        [ 101, 2797, 3582,  ...,    0,    0,    0],\n",
      "        [ 101, 2797, 3582,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  523, 7278,  ...,    0,    0,    0],\n",
      "        [ 101, 7442,  928,  ...,    0,    0,    0],\n",
      "        [ 101, 6313, 1558,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "8\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "{'labels': tensor([nan, nan, nan, nan, nan, nan, nan, nan]), 'input_ids': tensor([[ 101,  138, 1558,  ...,    0,    0,    0],\n",
      "        [ 101, 6313, 1558,  ...,    0,    0,    0],\n",
      "        [ 101,  138, 5632,  ...,  943, 3760,  102],\n",
      "        ...,\n",
      "        [ 101, 6895, 1001,  ...,    0,    0,    0],\n",
      "        [ 101, 8847,  131,  ...,    0,    0,    0],\n",
      "        [ 101, 8847,  131,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "8\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "{'labels': tensor([nan]), 'input_ids': tensor([[ 101, 8847,  131,  138, 2658, 1841,  140,  765, 1922, 7442,  928, 8024,\n",
      "          856, 1019, 3175, 3428,  523, 1372, 1168,  791, 1921,  524,  511,  138,\n",
      "         9463,  140, 6895, 1001, 4268, 4268,  679, 5183, 8024,  872, 2218,  679,\n",
      "         5543, 6794, 8024, 1378, 1520, 4268, 4268,  679, 5183, 8024, 1378, 3215,\n",
      "         2218, 6857, 3564,  749, 5265, 5147,  914, 3428, 6917, 3760, 7302, 8024,\n",
      "         2797,  677, 3175, 3428, 6917, 5543, 6158, 3819,  671, 3797,  102,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "1\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 預測\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred=evaluation(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83d1e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理結果\n",
    "my_predict = df_test_all.join(pd.DataFrame(y_pred))\n",
    "my_predict.rename(columns={0 : 'drop'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21bb3d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>tags</th>\n",
       "      <th>drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97871d38-daaf-57ea-bfbd-941c18216ca9</td>\n",
       "      <td>2022-03-16 12:00:01</td>\n",
       "      <td>https://www.facebook.com/144526625731445/posts...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5000積分活動通知] 遠傳電信 新申辦、攜碼 手機合約 活動，請立即登入JAG手機App...</td>\n",
       "      <td>fans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>主文</td>\n",
       "      <td>其他</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>018e9ee3-e250-509b-991c-a22f5e4318a7</td>\n",
       "      <td>2022-03-15 00:57:00</td>\n",
       "      <td>https://www.mobile01.com/topicdetail.php?f=568...</td>\n",
       "      <td>請問購買S22 ultra的各位 網路是都直上5G訊號嗎？</td>\n",
       "      <td>\\n遠傳319 4G吃到飽路過....s22ultra\\n</td>\n",
       "      <td>mobile01_comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>回文</td>\n",
       "      <td>網速</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c9839fab-e1c9-51e0-8b60-14330dd85d65</td>\n",
       "      <td>2022-03-14 10:25:00</td>\n",
       "      <td>https://www.mobile01.com/topicdetail.php?f=18&amp;...</td>\n",
       "      <td>遠傳5g近期的速度</td>\n",
       "      <td>\\n中華5G建設也滿積極的 網路涵蓋有越來越廣\\n前陣子去高雄看花燈人很多 網速還有破800...</td>\n",
       "      <td>mobile01_comment</td>\n",
       "      <td>高雄</td>\n",
       "      <td>回文</td>\n",
       "      <td>網速</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id                 date  \\\n",
       "8   97871d38-daaf-57ea-bfbd-941c18216ca9  2022-03-16 12:00:01   \n",
       "10  018e9ee3-e250-509b-991c-a22f5e4318a7  2022-03-15 00:57:00   \n",
       "14  c9839fab-e1c9-51e0-8b60-14330dd85d65  2022-03-14 10:25:00   \n",
       "\n",
       "                                                  url  \\\n",
       "8   https://www.facebook.com/144526625731445/posts...   \n",
       "10  https://www.mobile01.com/topicdetail.php?f=568...   \n",
       "14  https://www.mobile01.com/topicdetail.php?f=18&...   \n",
       "\n",
       "                            title  \\\n",
       "8                             NaN   \n",
       "10  請問購買S22 ultra的各位 網路是都直上5G訊號嗎？   \n",
       "14                      遠傳5g近期的速度   \n",
       "\n",
       "                                              content            source  \\\n",
       "8   [5000積分活動通知] 遠傳電信 新申辦、攜碼 手機合約 活動，請立即登入JAG手機App...              fans   \n",
       "10                      \\n遠傳319 4G吃到飽路過....s22ultra\\n  mobile01_comment   \n",
       "14  \\n中華5G建設也滿積極的 網路涵蓋有越來越廣\\n前陣子去高雄看花燈人很多 網速還有破800...  mobile01_comment   \n",
       "\n",
       "   location type tags  drop  \n",
       "8       NaN   主文   其他   1.0  \n",
       "10      NaN   回文   網速   1.0  \n",
       "14       高雄   回文   網速   1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop之內容\n",
    "df_drop = my_predict.loc[my_predict['drop']==1]#.loc[:,'title':'date']\n",
    "\n",
    "# 紀錄過濾掉的資料\n",
    "drop_final_save_path_file = './../data/no_use_data/'\n",
    "drop_final_save_path = os.path.join(drop_final_save_path_file,'data_'+date+'.csv')\n",
    "df_drop.to_csv(drop_final_save_path,index=False)\n",
    "\n",
    "df_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d72ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>tags</th>\n",
       "      <th>drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97871d38-daaf-57ea-bfbd-941c18216ca9</td>\n",
       "      <td>2022-03-16 12:00:01</td>\n",
       "      <td>https://www.facebook.com/144526625731445/posts...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5000積分活動通知] 遠傳電信 新申辦、攜碼 手機合約 活動，請立即登入JAG手機App...</td>\n",
       "      <td>fans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>主文</td>\n",
       "      <td>其他</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>018e9ee3-e250-509b-991c-a22f5e4318a7</td>\n",
       "      <td>2022-03-15 00:57:00</td>\n",
       "      <td>https://www.mobile01.com/topicdetail.php?f=568...</td>\n",
       "      <td>請問購買S22 ultra的各位 網路是都直上5G訊號嗎？</td>\n",
       "      <td>\\n遠傳319 4G吃到飽路過....s22ultra\\n</td>\n",
       "      <td>mobile01_comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>回文</td>\n",
       "      <td>網速</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c9839fab-e1c9-51e0-8b60-14330dd85d65</td>\n",
       "      <td>2022-03-14 10:25:00</td>\n",
       "      <td>https://www.mobile01.com/topicdetail.php?f=18&amp;...</td>\n",
       "      <td>遠傳5g近期的速度</td>\n",
       "      <td>\\n中華5G建設也滿積極的 網路涵蓋有越來越廣\\n前陣子去高雄看花燈人很多 網速還有破800...</td>\n",
       "      <td>mobile01_comment</td>\n",
       "      <td>高雄</td>\n",
       "      <td>回文</td>\n",
       "      <td>網速</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id                 date  \\\n",
       "8   97871d38-daaf-57ea-bfbd-941c18216ca9  2022-03-16 12:00:01   \n",
       "10  018e9ee3-e250-509b-991c-a22f5e4318a7  2022-03-15 00:57:00   \n",
       "14  c9839fab-e1c9-51e0-8b60-14330dd85d65  2022-03-14 10:25:00   \n",
       "\n",
       "                                                  url  \\\n",
       "8   https://www.facebook.com/144526625731445/posts...   \n",
       "10  https://www.mobile01.com/topicdetail.php?f=568...   \n",
       "14  https://www.mobile01.com/topicdetail.php?f=18&...   \n",
       "\n",
       "                            title  \\\n",
       "8                             NaN   \n",
       "10  請問購買S22 ultra的各位 網路是都直上5G訊號嗎？   \n",
       "14                      遠傳5g近期的速度   \n",
       "\n",
       "                                              content            source  \\\n",
       "8   [5000積分活動通知] 遠傳電信 新申辦、攜碼 手機合約 活動，請立即登入JAG手機App...              fans   \n",
       "10                      \\n遠傳319 4G吃到飽路過....s22ultra\\n  mobile01_comment   \n",
       "14  \\n中華5G建設也滿積極的 網路涵蓋有越來越廣\\n前陣子去高雄看花燈人很多 網速還有破800...  mobile01_comment   \n",
       "\n",
       "   location type tags  drop  \n",
       "8       NaN   主文   其他   1.0  \n",
       "10      NaN   回文   網速   1.0  \n",
       "14       高雄   回文   網速   1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_predict.loc[my_predict['drop']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c4107f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noc\\AppData\\Local\\Temp\\ipykernel_8660\\934464932.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.drop(columns='drop',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 留下非drop之資料並輸出\n",
    "result = my_predict.loc[my_predict['drop']==0]\n",
    "result.drop(columns='drop',inplace=True)\n",
    "\n",
    "\n",
    "# # 列出crawel_type                                   \n",
    "# crawel_type = [f.split(\"_\")[0] for f in result[\"filename\"]]\n",
    "# crawel_type\n",
    "\n",
    "# result['crawel_type'] = crawel_type\n",
    "# result.drop(columns='filename',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08485e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_save_path_file = './../data/'\n",
    "final_save_path = os.path.join(final_save_path_file,'final_'+date+'.csv')\n",
    "result.to_csv(final_save_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "407d41f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------save ok------------------------\n",
      "Save path:./../data/final_2022-03-18.csv\n",
      "Original data : 1918, Keep data: 14, Drop data:3\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------save ok------------------------')\n",
    "print(f'Save path:{final_save_path}')\n",
    "print(f'Original data : {len(my_predict)}, Keep data: {len(result)}, Drop data:{len(df_drop)}')\n",
    "print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a6e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4e0fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook drop_model_bigtree.ipynb to script\n",
      "[NbConvertApp] Writing 10101 bytes to drop_model_bigtree.py\n"
     ]
    }
   ],
   "source": [
    "#If you want to convert all *.ipynb files from current directory to python script, you can run the command like this:\n",
    "#!pip install ipython\n",
    "#!pip install nbconvert\n",
    "#!jupyter nbconvert --to script *.ipynb(轉換成 *.py)\n",
    "\n",
    "# 只要執行一次, 更新*.py,即可remark, \n",
    "# 若要用 docker, 要將 *.py中的 pip install transformer 註解, docker有安裝\n",
    "\n",
    "! jupyter nbconvert --to script drop_model_bigtree.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f4de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93142bfb35f5afb420ab1de6cb1e3c843ba21cfc0819b7ae0900097ae81dc343"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
