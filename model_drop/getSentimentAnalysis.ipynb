{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e3ef5c",
   "metadata": {},
   "source": [
    "## Step1：取得資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dafef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import date\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "d1 = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "# d1 = '2022-01-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7af5ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['crawel_type'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/final_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)   \n\u001b[1;32m----> 2\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m發文者\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m標題\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m推回文類別\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m內容\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m發文時間\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m觀看次數\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m推噓評價\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m發文者分數\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mURL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrawel_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['crawel_type'] not in index\""
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/final_' + d1 + '.csv', sep=',')   \n",
    "df_raw = df[['發文者','標題','推回文類別','內容','發文時間','觀看次數','推噓評價','發文者分數','URL','crawel_type']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9ebe1",
   "metadata": {},
   "source": [
    "## Step2: 取得各家情緒分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1273c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.8.28)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers #--use-feature=2020-resolver #requests beautifulsoup4 pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "df_raw.loc[:,'corpus'] = df['標題'].fillna(' ') + \": \" + df['內容'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditionFilter = 'and ~(corpus.str.contains(\"廣告\"))'\n",
    "conditionFET = 'corpus.str.contains(\"遠傳|FET\") '\n",
    "conditionCHT = 'corpus.str.contains(\"中華|CHT\") '\n",
    "conditionGT = 'corpus.str.contains(\"亞太|APGT\") '\n",
    "conditionTWN = 'corpus.str.contains(\"台哥大|台灣大|TWN\") '\n",
    "conditionTWNS = 'corpus.str.contains(\"台星|台灣之星\") '\n",
    "\n",
    "df_FET = df_raw.query(conditionFET + conditionFilter , engine='python')\n",
    "df_CHT = df_raw.query(conditionCHT + conditionFilter , engine='python')\n",
    "df_GT = df_raw.query(conditionGT + conditionFilter , engine='python')\n",
    "df_TWN = df_raw.query(conditionTWN + conditionFilter , engine='python')\n",
    "df_TWNS = df_raw.query(conditionTWNS + conditionFilter , engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf8e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(105890, 768)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('adamlin/bert-distil-chinese')\n",
    "\n",
    "tokenizer.add_tokens(['遠傳','亞太','中華','台哥大','台灣大哥大','台星','台灣之星','5g','4g','5G','4G'], special_tokens=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model.aux_logits = False\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c4b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>發文者</th>\n",
       "      <th>標題</th>\n",
       "      <th>推回文類別</th>\n",
       "      <th>內容</th>\n",
       "      <th>發文時間</th>\n",
       "      <th>觀看次數</th>\n",
       "      <th>推噓評價</th>\n",
       "      <th>發文者分數</th>\n",
       "      <th>URL</th>\n",
       "      <th>crawel_type</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>茶太</td>\n",
       "      <td>台星最快也要第三季才能合併</td>\n",
       "      <td>主文</td>\n",
       "      <td>也就是說我還有申請一個月免費試用機會。</td>\n",
       "      <td>2022-01-04 23:31</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3380分</td>\n",
       "      <td>https://www.google.com.tw/url?q=https://www.mo...</td>\n",
       "      <td>Mobile01</td>\n",
       "      <td>台星最快也要第三季才能合併: 也就是說我還有申請一個月免費試用機會。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kti</td>\n",
       "      <td>台星最快也要第三季才能合併</td>\n",
       "      <td>回文</td>\n",
       "      <td>茶太 wrote:\\n也就是說我還有申請一...(恕刪)\\n\\n喔\\n原來你沒有\\n也難怪了</td>\n",
       "      <td>2022-01-05 1:34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879分</td>\n",
       "      <td>https://www.google.com.tw/url?q=https://www.mo...</td>\n",
       "      <td>Mobile01</td>\n",
       "      <td>台星最快也要第三季才能合併: 茶太 wrote:\\n也就是說我還有申請一...(恕刪)\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iosapp</td>\n",
       "      <td>台星最快也要第三季才能合併</td>\n",
       "      <td>回文</td>\n",
       "      <td>不知\\n將來合併 以後 原本 台星\\n1.自由配 還會繼續存在嗎?\\n2.以前辦的 新朋友 ...</td>\n",
       "      <td>2022-01-05 12:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>147分</td>\n",
       "      <td>https://www.google.com.tw/url?q=https://www.mo...</td>\n",
       "      <td>Mobile01</td>\n",
       "      <td>台星最快也要第三季才能合併: 不知\\n將來合併 以後 原本 台星\\n1.自由配 還會繼續存在...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      發文者             標題 推回文類別  \\\n",
       "0      茶太  台星最快也要第三季才能合併    主文   \n",
       "1     kti  台星最快也要第三季才能合併    回文   \n",
       "2  iosapp  台星最快也要第三季才能合併    回文   \n",
       "\n",
       "                                                  內容              發文時間  \\\n",
       "0                                也就是說我還有申請一個月免費試用機會。  2022-01-04 23:31   \n",
       "1     茶太 wrote:\\n也就是說我還有申請一...(恕刪)\\n\\n喔\\n原來你沒有\\n也難怪了   2022-01-05 1:34   \n",
       "2  不知\\n將來合併 以後 原本 台星\\n1.自由配 還會繼續存在嗎?\\n2.以前辦的 新朋友 ...  2022-01-05 12:45   \n",
       "\n",
       "     觀看次數  推噓評價  發文者分數                                                URL  \\\n",
       "0  1914.0   0.0  3380分  https://www.google.com.tw/url?q=https://www.mo...   \n",
       "1     0.0   0.0   879分  https://www.google.com.tw/url?q=https://www.mo...   \n",
       "2     0.0   5.0   147分  https://www.google.com.tw/url?q=https://www.mo...   \n",
       "\n",
       "  crawel_type                                             corpus  \n",
       "0    Mobile01                 台星最快也要第三季才能合併: 也就是說我還有申請一個月免費試用機會。  \n",
       "1    Mobile01  台星最快也要第三季才能合併: 茶太 wrote:\\n也就是說我還有申請一...(恕刪)\\n\\...  \n",
       "2    Mobile01  台星最快也要第三季才能合併: 不知\\n將來合併 以後 原本 台星\\n1.自由配 還會繼續存在...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(com_type, corpus, content):\n",
    "    \n",
    "    if content.find(com_type):\n",
    "        corpus = content \n",
    "        #若內文有公司名稱,直接以內文分析, 標題不列入情緒分析\n",
    "        #若內文沒有公司名稱, 則以主題+內文分析.\n",
    "        #若只考慮內文,會有多筆都沒評分.\n",
    "    \n",
    "    tokens = tokenizer.encode(text=com_type, text_pair=corpus, \n",
    "                              return_tensors='pt', add_special_tokens = True)\n",
    "#     print(tokens[:100])\n",
    "#     print(tokenizer.convert_ids_to_tokens(tokens.squeeze())[:100])\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "\n",
    "com_arr = ['FET','GT','CHT','TWN','TWNS']\n",
    "com_name_arr = ['遠傳','亞太','中華','台哥大或台灣大哥大','台星或台灣之星']\n",
    "\n",
    "for i, v in enumerate(com_arr) :\n",
    "#     print(com_name_arr[i])\n",
    "#     print(len(locals()['df_'+v].index))\n",
    "#     print(pd.DataFrame(locals()['df_'+v]['corpus']).head(1))\n",
    "    df_raw['score'+v] = \" \"\n",
    "    if len(locals()['df_'+v].index) :\n",
    "        df_raw['score'+v] = pd.DataFrame(locals()['df_'+v]).apply(lambda r : get_score('對'+ com_name_arr[i] +'的看法:',\n",
    "                                                                                       r['corpus'][:500], r['內容'][:500]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfed047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_raw[['發文者','標題','推回文類別','內容','發文時間','觀看次數','推噓評價','發文者分數','URL','crawel_type'\n",
    "                   ,'scoreFET','scoreTWN','scoreCHT','scoreGT','scoreTWNS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_csv('./../crawler_data/clean_data/data_' + d1 + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('final_' + d1 + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63224857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa815284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd4f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
